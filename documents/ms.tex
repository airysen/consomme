\documentclass[12pt,preprint]{aastex}

\newcommand{\equationname}{equation}
\newcommand{\equationnames}{\equationname s}
\newcommand{\given}{\,|\,}
\newcommand{\setof}[1]{\left\{{#1}\right\}}
\newcommand{\transpose}[1]{{#1}^{\!{\mathsf{T}}}}

% Stolen from DFM's emcee paper - trim later
\newcommand{\project}[1]{{\sffamily #1}}
\newcommand{\Python}{\project{Python}}
\newcommand{\numpy}{\project{numpy}}
\newcommand{\Ubuntu}{\project{Ubuntu}}
\newcommand{\github}{\project{GitHub}}
\newcommand{\pip}{\project{pip}}
\newcommand{\acor}{\project{acor}}
\newcommand{\sdss}{\project{SDSS}}
\newcommand{\hfaplain}{HFA}
\newcommand{\hfa}{\project{\hfaplain}}
\newcommand{\paper}{document}
\newcommand{\license}{GNU General Public License v2}

\begin{document}

\title{Heteroskedastic Factor Analysis}

\newcommand{\nyu}{2}
\newcommand{\mpia}{3}
\author{Ross~Fadely\altaffilmark{1,\nyu},
    David~W.~Hogg\altaffilmark{\nyu,\mpia}}
\altaffiltext{1}{To whom correspondence should be addressed:
                        \url{rossfadely@nyu.edu}}
\altaffiltext{\nyu}{Center for Cosmology and Particle Physics,
                        Department of Physics, New York University,
                        4 Washington Place, New York, NY, 10003, USA}
\altaffiltext{\mpia}{Max-Planck-Institut f\"ur Astronomie,
                     K\"onigstuhl 17, D-69117 Heidelberg, Germany}

\begin{abstract}

    Principal Components Analysis (PCA) is a widely used method in 
    Astronomy (and other disciplines) to construct a low-dimensional 
    representation of the data covariance.  A major problem with PCA 
    is that it fails to account for differences in measurement 
    uncertainties, both within and across observations.  As a 
    consequence, the performance of PCA is severely compromised when 
    the numbers of observations are small, with noise properties that 
    are non-uniform and/or large.  We present a method for generalized 
    dimensionality reduction under the presence of heterogeneous, 
    noisy observations.  The method, dubbed \project{Heteroskedastic 
    Factor Analysis} or \hfa\ , represents a modified version of 
    Factor Analysis which utilizes the observed uncertainties and can 
    naturally account for missing or bad data.  We demonstrate the 
    relative performances of standard PCA, 
    Expectation-Maximization PCA (EM-PCA), Factor Analysis, and \hfa\
    on toy data, as well as (realistically modified) spectra from the 
    Sloan Digital Sky Survey (\sdss).  Finally, we apply \hfa\ to ...

\end{abstract}

\keywords{
    methods: data analysis ---
    methods: numerical ---
    methods: statistical
}

~\clearpage

\noindent

\section{Introduction}

To say -
\begin{itemize}
\item PCA is widely used
\item Noisy observations ruin PCA (under low $N$ samples)
\item There are some traditional workarounds
\end{itemize}


\section{Dimensionality Reduction using Matrix Factorization}

\subsection{Principle Components Analysis}


\end{document}
